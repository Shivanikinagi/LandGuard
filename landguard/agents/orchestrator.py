# """
# Workflow Orchestrator
# Coordinates the autonomous agents for complete document processing workflow
# """

# import asyncio
# import uuid
# from typing import List, Dict, Any
# from datetime import datetime

# from .base_agent import BaseAgent
# from .anomaly_detection_agent import AnomalyDetectionAgent
# from .compression_agent import CompressionAgent
# from .storage_agent import StorageAgent

# class WorkflowOrchestrator:
#     """Orchestrate the complete document processing workflow through autonomous agents"""
    
#     def __init__(self, encryption_password: str = "landguard_default"):
#         self.agents: List[BaseAgent] = [
#             AnomalyDetectionAgent(),
#             CompressionAgent(password=encryption_password),
#             StorageAgent()
#         ]
#         self.workflow_history = []
#         self.created_at = datetime.utcnow()
    
#     async def process_document(self, file_path: str) -> Dict[str, Any]:
#         """Process a document through the complete agentic workflow"""
#         workflow_id = str(uuid.uuid4())
#         workflow_start = asyncio.get_event_loop().time()
        
#         print(f"ğŸš€ LANDGUARD AUTONOMOUS WORKFLOW")
#         print("=" * 40)
#         print(f"ğŸ“„ Document: {file_path}")
#         print(f"ğŸ†” Workflow ID: {workflow_id}")
#         print(f"â±ï¸  Start Time: {self.created_at.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        
#         # Step 1: Anomaly Detection
#         print(f"\nğŸ•µï¸ STEP 1: FRAUD DETECTION")
#         print("-" * 25)
        
#         anomaly_agent = self._get_agent("anomaly_detector")
#         anomaly_task = {
#             "file_path": file_path
#         }
        
#         anomaly_result = await anomaly_agent.process(anomaly_task)
        
#         # Add success flag for consistency
#         anomaly_result["success"] = True
        
#         if anomaly_result.get("success"):
#             risk_score = anomaly_result.get("risk_score", 0)
#             anomalies = anomaly_result.get("anomalies", [])
            
#             print(f"âœ… Analysis complete")
#             print(f"ğŸ“Š Risk Score: {risk_score}/10")
#             print(f"âš ï¸  Anomalies: {len(anomalies)} detected")
            
#             if anomalies:
#                 for anomaly in anomalies[:3]:  # Show first 3 anomalies
#                     print(f"   â€¢ {anomaly.get('description', anomaly.get('type', 'Unknown anomaly'))}")
#                 if len(anomalies) > 3:
#                     print(f"   â€¢ ... and {len(anomalies) - 3} more")
#         else:
#             print(f"âŒ Analysis failed: {anomaly_result.get('error')}")
            
#         # Step 2: Compression and Encryption
#         print(f"\nğŸ” STEP 2: SECURITY PROCESSING")
#         print("-" * 25)
        
#         compression_agent = self._get_agent("compression_agent")
#         compression_task = {
#             "file_path": file_path,
#             "risk_score": anomaly_result.get("risk_score", 5.0),
#             "anomalies": anomaly_result.get("anomalies", [])
#         }
        
#         compression_result = await compression_agent.process(compression_task)
        
#         # Add success flag if missing
#         if "success" not in compression_result:
#             compression_result["success"] = compression_result.get("output_path") is not None
        
#         if compression_result.get("success"):
#             print(f"âœ… Compression successful")
#             print(f"ğŸ“ Output: {compression_result.get('output_path')}")
#             print(f"ğŸ“Š Ratio: {compression_result.get('compression_ratio', 1.0)}x")
#             print(f"ğŸ›¡ï¸ Method: {compression_result.get('method')}")
#         else:
#             print(f"âŒ Compression failed: {compression_result.get('error')}")
            
#         # Step 3: Storage on IPFS and Blockchain
#         print(f"\nğŸŒ STEP 3: DISTRIBUTED STORAGE")
#         print("-" * 25)
        
#         storage_agent = self._get_agent("storage_agent")
#         storage_task = {
#             "file_path": compression_result.get("output_path", file_path),
#             "original_file": file_path
#         }
        
#         storage_result = await storage_agent.process(storage_task)
        
#         # Print storage results
#         ipfs_result = storage_result.get("ipfs", {})
#         blockchain_result = storage_result.get("blockchain", {})
        
#         if ipfs_result.get("success"):
#             print(f"âœ… IPFS Upload Successful")
#             print(f"ğŸ”— CID: {ipfs_result.get('cid')}")
#             print(f"ğŸŒ Nodes: {ipfs_result.get('nodes')} nodes")
#         else:
#             print(f"âŒ IPFS Upload Failed: {ipfs_result.get('error')}")
            
#         if blockchain_result.get("success"):
#             print(f"âœ… Blockchain Registration Successful")
#             print(f"ğŸ”— TX: {blockchain_result.get('transaction_hash')[:16]}...")
#             print(f"â›“ï¸ Network: {blockchain_result.get('network')}")
            
#             # Show explorer link for real transactions
#             method = blockchain_result.get('method', '')
#             if 'REAL' in method.upper():
#                 tx_hash = blockchain_result.get('transaction_hash')
#                 if tx_hash.startswith('0x'):
#                     # Use the polygon handler's explorer URL method
#                     try:
#                         from ..Blockchain.blockchain.polygon_handler import PolygonHandler
#                         handler = PolygonHandler()
#                         explorer_url = handler.get_explorer_url(tx_hash)
#                         print(f"ğŸ” Explorer: {explorer_url}")
#                     except:
#                         # Fallback to direct URL construction
#                         explorer_url = f"https://mumbai.polygonscan.com/tx/{tx_hash}"
#                         print(f"ğŸ” Explorer: {explorer_url}")
#         else:
#             print(f"âŒ Blockchain Registration Failed: {blockchain_result.get('error')}")
            
#         # Compile final results
#         workflow_duration = asyncio.get_event_loop().time() - workflow_start
#         final_result = {
#             "workflow_id": workflow_id,
#             "file_path": file_path,
#             "anomaly_detection": anomaly_result,
#             "compression": compression_result,
#             "storage": storage_result,
#             "duration_seconds": round(workflow_duration, 2),
#             "timestamp": asyncio.get_event_loop().time()
#         }
        
#         self.workflow_history.append(final_result)
        
#         # Print final summary
#         print(f"\nâœ… WORKFLOW COMPLETE")
#         print("=" * 20)
#         print(f"â±ï¸ Duration: {final_result['duration_seconds']}s")
        
#         if ipfs_result.get("success") and blockchain_result.get("success"):
#             print(f"ğŸ”’ Document secured on blockchain")
#             print(f"ğŸ†” Verification CID: {ipfs_result.get('cid')}")
#             print(f"ğŸ“ TX: {blockchain_result.get('transaction_hash')}")
            
#             # Show explorer link for real transactions
#             method = blockchain_result.get('method', '')
#             if 'REAL' in method.upper():
#                 tx_hash = blockchain_result.get('transaction_hash')
#                 if tx_hash.startswith('0x'):
#                     # Use the polygon handler's explorer URL method
#                     try:
#                         from ..Blockchain.blockchain.polygon_handler import PolygonHandler
#                         handler = PolygonHandler()
#                         explorer_url = handler.get_explorer_url(tx_hash)
#                         print(f"ğŸŒ View on Explorer: {explorer_url}")
#                     except:
#                         # Fallback to direct URL construction
#                         explorer_url = f"https://mumbai.polygonscan.com/tx/{tx_hash}"
#                         print(f"ğŸŒ View on Explorer: {explorer_url}")
            
#         print(f"\nğŸ” VERIFICATION COMMAND:")
#         print(f"landguard-agents verify {ipfs_result.get('cid', 'CID_NOT_AVAILABLE')}")
        
#         return final_result
        
#     def _get_agent(self, agent_name: str) -> BaseAgent:
#         """Get agent by name"""
#         for agent in self.agents:
#             if agent.name == agent_name:
#                 return agent
#         raise ValueError(f"Agent {agent_name} not found")
        
#     def get_agent_status(self) -> Dict[str, Any]:
#         """Get status of all agents"""
#         return {
#             agent.name: agent.get_status() for agent in self.agents
#         }
        
#     def verify_document(self, cid: str) -> Dict[str, Any]:
#         """Verify a document using the storage agent"""
#         storage_agent = self._get_agent("storage_agent")
#         return storage_agent.verify_document(cid)

# # Convenience function for easy use
# async def process_land_document(file_path: str) -> Dict[str, Any]:
#     """Convenience function to process a land document"""
#     orchestrator = WorkflowOrchestrator()
#     return await orchestrator.process_document(file_path)


"""
Workflow Orchestrator
Coordinates the autonomous agents for complete document processing workflow.

This version implements an *interactive* agentic flow:
1. Run anomaly / fraud analysis and show results to the user.
2. Ask for permission (yes/no) to encrypt the data.
3. Ask for permission (yes/no) to compress the data.
4. Proceed with .ppc creation, IPFS upload, optional blockchain registration.
"""

import asyncio
import os
import sys
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime, time

from .base_agent import BaseAgent
from .anomaly_detection_agent import AnomalyDetectionAgent
from .compression_agent import CompressionAgent
from .storage_agent import StorageAgent


class WorkflowOrchestrator:
    """Orchestrate the complete document processing workflow through autonomous agents"""

    def __init__(self, encryption_password: str = "landguard_default", interactive: bool = True):
        self.agents: List[BaseAgent] = [
            AnomalyDetectionAgent(),
            CompressionAgent(password=encryption_password),
            StorageAgent(),
        ]
        self.workflow_history: List[Dict[str, Any]] = []
        self.created_at = datetime.utcnow()
        self.interactive = interactive
        self.spinner_frames = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
        self.spinner_idx = 0

    # -------------------------------------------------------------------------
    # Visual Helper Methods
    # -------------------------------------------------------------------------
    async def _animate_step(self, duration: float = 0.5):
        """Smooth animation with spinner"""
        steps = int(duration * 20)
        for _ in range(steps):
            await asyncio.sleep(duration / steps)

    async def _step(self, number: int, title: str):
        """Display step header with animation"""
        await asyncio.sleep(0.2)
        print(f"\n  âœ¦ STEP {number}: {title}")
        print(f"  {'â”€' * (len(title) + 14)}")
        await asyncio.sleep(0.15)

    def _print_status(self, icon: str, message: str, detail: str = ""):
        """Print a status line with consistent formatting"""
        if detail:
            print(f"  {icon}  {message}")
            print(f"     â””â”€ {detail}")
        else:
            print(f"  {icon}  {message}")

    def _print_section(self, title: str):
        """Print a formatted section header"""
        print(f"\n  â•­â”€ {title}")

    def _print_item(self, label: str, value: Any, indent: int = 1):
        """Print a labeled item with smart truncation"""
        prefix = "  â”‚   " if indent == 1 else "      "
        value_str = str(value)
        # Truncate long values intelligently
        if len(value_str) > 60:
            value_str = value_str[:57] + "â€¦"
        print(f"{prefix}â€¢ {label}: {value_str}")

    def _print_section_end(self):
        """Print section footer"""
        print(f"  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    async def _delayed_print(self, message: str, delay: float = 0.1):
        """Print message with smooth delay"""
        await asyncio.sleep(delay)
        print(message)

    # -------------------------------------------------------------------------
    # Public API
    # -------------------------------------------------------------------------
    async def process_document(self, file_path: str, *, encrypt=None, compress=None, enable_blockchain=None):
        """Main workflow entry point with enhanced visuals"""

        workflow_id = str(uuid.uuid4())
        
        # Title banner
        print("\n" + "  " + "â•­" + "â”€" * 50 + "â•®")
        print("  " + "â”‚" + "  ğŸš€  LANDGUARD AUTONOMOUS WORKFLOW INITIALIZED  " + "â”‚")
        print("  " + "â•°" + "â”€" * 50 + "â•¯")
        
        print(f"\n  ğŸ“„  File Path:    {os.path.basename(file_path)}")
        print(f"  ğŸ”‘  Workflow ID:  {workflow_id[:12]}â€¦")
        
        await self._animate_step(0.4)

        # STEP 1 â€” LOAD + VALIDATION
        await self._step(1, "Loading & Validating Document")
        self._print_status("ğŸ“–", "Reading file into workflowâ€¦")

        if not os.path.exists(file_path):
            self._print_status("âŒ", "File not found â€” stopping workflow")
            return

        await self._animate_step(0.3)
        self._print_status("âœ“", "Document loaded successfully")

        # STEP 2 â€” ANOMALY CHECK
        await self._step(2, "Fraud Detection & Risk Analysis")
        self._print_status("ğŸ”", "Analyzing document for anomaliesâ€¦")
        
        anomaly_agent = self._get_agent("anomaly_detector")
        anomaly_res = await anomaly_agent.process({"file_path": file_path})
        
        await self._animate_step(0.2)
        
        risk_score = anomaly_res["risk_score"]
        risk_icon = "ğŸŸ¢" if risk_score < 3 else "ğŸŸ¡" if risk_score < 6 else "ğŸ”´"
        
        self._print_status("âœ“", f"Analysis complete â€” Risk Score: {risk_icon} {risk_score}/10")
        
        if anomaly_res["anomalies"]:
            self._print_section("Detected Issues")
            for i, a in enumerate(anomaly_res["anomalies"][:4], 1):
                severity_icon = "âš ï¸ " if a.get('severity') == 'HIGH' else "â„¹ï¸ " if a.get('severity') == 'LOW' else "âš¡"
                self._print_item(
                    f"{severity_icon}{a['type']}", 
                    a['description'][:50] + "â€¦" if len(a['description']) > 50 else a['description']
                )
            if len(anomaly_res["anomalies"]) > 4:
                print(f"  â”‚   â€¦ and {len(anomaly_res['anomalies']) - 4} more issues detected")
            self._print_section_end()

        # STEP 3 â€” USER PERMISSION
        await self._step(3, "Requesting Security Permissions")
        
        encrypt = encrypt if encrypt is not None else self._ask_yes_no("ğŸ” Encrypt file?")
        compress = compress if compress is not None else self._ask_yes_no("ğŸ—œ  Compress file?")
        enable_blockchain = enable_blockchain if enable_blockchain is not None else self._ask_yes_no("â›“  Store on blockchain?")

        await self._animate_step(0.2)
        
        self._print_section("Security Configuration")
        self._print_item("Encryption", "âœ“ ON" if encrypt else "âœ— OFF")
        self._print_item("Compression", "âœ“ ON" if compress else "âœ— OFF")
        self._print_item("Blockchain", "âœ“ ON" if enable_blockchain else "âœ— OFF")
        self._print_section_end()

        # STEP 4 â€” COMPRESSION/ENCRYPTION
        await self._step(4, "Creating Secured PPC Package")
        self._print_status("ğŸ“¦", "Building encrypted containerâ€¦")
        
        compression_agent = self._get_agent("compression_agent")
        comp_res = await compression_agent.process({"file_path": file_path, "encrypt": encrypt, "compress": compress})
        
        await self._animate_step(0.25)
        
        output_filename = os.path.basename(comp_res['output_path'])
        self._print_status("âœ“", "PPC package created", f"File: {output_filename}")

        # STEP 5 â€” IPFS STORAGE
        await self._step(5, "Uploading to Distributed Storage")
        self._print_status("ğŸŒ", "Publishing to IPFS networkâ€¦")
        
        storage_agent = self._get_agent("storage_agent")
        store_res = await storage_agent.process({"file_path": comp_res['output_path'], "enable_blockchain": enable_blockchain})

        await self._animate_step(0.3)
        
        if store_res["ipfs"]["success"]:
            self._print_status("âœ“", "IPFS upload successful", f"CID: {store_res['ipfs']['cid'][:20]}â€¦")
        else:
            self._print_status("âŒ", "IPFS upload failed")

        # STEP 6 â€” BLOCKCHAIN REGISTRATION
        await self._step(6, "Blockchain Verification")
        
        if enable_blockchain and store_res["blockchain"]["success"]:
            self._print_status("â›“", "Blockchain registration complete", 
                             f"TX: {store_res['blockchain']['transaction_hash'][:16]}â€¦")
            await self._animate_step(0.25)
        else:
            self._print_status("â„¹ï¸ ", "Blockchain storage disabled")

        # FINAL STATUS
        await self._step(7, "Finalizing & Audit Trail")
        await self._animate_step(0.3)
        
        # Success banner
        print("\n" + "  " + "â•­" + "â”€" * 50 + "â•®")
        print("  " + "â”‚" + "  âœ“  WORKFLOW COMPLETED SUCCESSFULLY              " + "â”‚")
        print("  " + "â•°" + "â”€" * 50 + "â•¯")
        
        # Verification info
        cid = store_res['ipfs']['cid']
        print(f"\n  ğŸ”—  Document CID:  {cid}")
        print(f"  ğŸ“‹  Verify using:  landguard-agents verify {cid[:20]}â€¦")
        
        # Show summary stats if available
        if comp_res.get('original_size'):
            original_size = comp_res.get('original_size', 0)
            compressed_size = comp_res.get('compressed_size', 0)
            ratio = comp_res.get('compression_ratio', 1.0)
            print(f"  ğŸ“Š  Statistics:")
            print(f"       Original: {self._format_bytes(original_size)}")
            print(f"       Encrypted: {self._format_bytes(compressed_size)}")
            print(f"       Ratio: {ratio}x")
        
        print()
        
    def _format_bytes(self, bytes_val: int) -> str:
        """Format bytes to human readable format"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if bytes_val < 1024.0:
                return f"{bytes_val:.1f}{unit}"
            bytes_val /= 1024.0
        return f"{bytes_val:.1f}TB"

        
    # ------------------------------------------------------------------
    # Helper methods
    # ------------------------------------------------------------------
    def _get_agent(self, agent_name: str) -> BaseAgent:
        """Get agent by name"""
        for agent in self.agents:
            if agent.name == agent_name:
                return agent
        raise ValueError(f"Agent {agent_name} not found")

    def get_agent_status(self) -> Dict[str, Any]:
        """Get status of all agents"""
        return {agent.name: agent.get_status() for agent in self.agents}

    def verify_document(self, cid: str) -> Dict[str, Any]:
        """Verify a document using the storage agent"""
        storage_agent = self._get_agent("storage_agent")
        return storage_agent.verify_document(cid)

    @staticmethod
    def _ask_yes_no(prompt: str, default: bool = True) -> bool:
        """Simple blocking yes/no prompt used in CLI workflows.

        This intentionally uses input() and is meant for terminal / interactive
        usage only.
        """
        default_str = "Y/n" if default else "y/N"
        while True:
            answer = input(f"{prompt} [{default_str}] ").strip().lower()
            if not answer:
                return default
            if answer in {"y", "yes"}:
                return True
            if answer in {"n", "no"}:
                return False
            print("Please answer 'y' or 'n'.")


# Convenience wrappers --------------------------------------------------------


async def process_land_document(file_path: str, password: str = "landguard_default") -> Dict[str, Any]:
    """Backwards-compatible helper to process a land document."""
    orchestrator = WorkflowOrchestrator(encryption_password=password, interactive=False)
    return await orchestrator.process_document(file_path)


async def process_document_agentic(
    file_path: str,
    password: str = "landguard_default",
    *,
    interactive: bool = True,
) -> Dict[str, Any]:
    """Entry point used by the CLI (landguard-agents).

    This will:
    - run anomaly analysis
    - ask user for encryption / compression / blockchain choices
    - run the full workflow accordingly
    """
    orchestrator = WorkflowOrchestrator(encryption_password=password, interactive=interactive)
    return await orchestrator.process_document(file_path)